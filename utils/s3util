#! /usr/bin/env python
# Script tp sync local directories into s3.
# Currently using s3 sync to achieve the same.
# Author: Ajay Mahto <ajay.mahto@grab.com>

import argparse
import logging
import os
import shlex
import socket
import sys

from datetime import date
from subprocess import Popen, PIPE

region = "ap-southeast-1"
retention_days = 10
loggingDir = "/var/log/s3util"
localDir = "/tmp"
bucketName = 'ajay-test-bucket01'
parser = argparse.ArgumentParser()

"""
Setting up logging.
"""
if not os.path.exists(loggingDir):
    os.makedirs(loggingDir)
logging.basicConfig(filename="/var/log/s3util/s3util.log", 
                    format='%(asctime)s %(message)s', 
                    filemode='a+') 
logger=logging.getLogger() 
logger.setLevel(logging.DEBUG)

def get_current_date():
    """
    Function to get the current date.
    Required for creating the s3key for backup.
    """
    return date.today().isoformat()

def create_s3keep(datestamp):
    """
    Placing a hidden file named .s3keep in every dir recursively.
    This is required to ensure the exact dir structure,
    as s3 does not allow empty path while uploading objects.
    """
    with open(".s3keep", "w") as f:
        f.write(str(datestamp))

def get_output(cmd):
    """
    Function to run shell commands that contain pipes.
    shell=True
    """
    p = Popen(cmd, shell=True, stderr=PIPE, stdout=PIPE)
    out, err = p.communicate()
    if out:
        ret = out.strip()
    else:
        ret = None
    return ret

def get_instance_hostname():
    """
    Function to return instance hostname using curl.
    This is required as instance_id is begin used as a prt of the
    s3key for storing backup.
    """
    return socket.gethostname()

def get_latest_backup_date(localDir):
    """
    Function to fetch the lastest date when the given directory in the current 
    instance was backed up.
    """
    hname = get_instance_hostname()
    cmd = "aws s3 ls --recursive s3://%s/%s | grep %s | awk '{print $1}' | sort | uniq | \
            head -n 1" % (bucketName, hname, localDir)
    return get_output(cmd)

def backup(localDir):
    """
    Function to backup.
    aws s3 sync ensures both syncing of files to and from s3.
    awscli needs to be installed for aws s3 sync to work.
    To install awscli simply run - pip install awscli.
    Steps:
    1. Places .s3keep file into every directory in the dir structure.
    2. Syncs path into s3 using aws s3 sync.
    3. Supports large file upload using multi-part upload.
    """
    if not os.path.exists(localDir):
        msg = "Missing source dir %s" % args.path
        print msg
        logger.error(msg)
        exit(1)
    hname = get_instance_hostname()
    msg = 'Placing .s3keep file in all paths.'
    logger.info(msg)
    today = get_current_date()
    create_s3keep(today)
    cmd = 'find %s -type d -not -path "./.git/*" \
            -exec cp ./.s3keep {}/.s3keep \;' % localDir
    
    if run_cmd(cmd):
        msg = '.s3keep placement success!'
        logger.info(msg)
    else:
        msg = '.s3keep placement failed!'
        logger.warning(msg)
    backupDate = get_current_date()
    s3Dir = "s3://%s/%s/%s%s" % (bucketName, hname, backupDate, \
            localDir)
    msg = "Backing Up %s to %s" % (localDir, s3Dir)
    print msg
    logger.info(msg)
    cmd = "aws s3 sync --delete %s %s" % (localDir, s3Dir)
    msg = "Command: %s" % cmd
    logger.info(msg)
    
    if run_cmd(cmd):
        msg = "Backup Successful!"
        print msg
        logger.info(msg)
        msg = "Removing Old Backups. Retention Days Set To : %s days" % \
                retention_days
        print msg
        logger.info(msg)
        remove_old_backups(localDir)
    else:
        msg = "Backup Failed!"
        print msg
        logger.info(msg)

def restore(localDir, restoreDate):
    """
    Function to restore directory from s3 into local system.
    restoreDate - Required parameter.
    aws s3 sync is being used internally to sync directory from s3 bucket.
    awscli needs to be configured beforehand for this function to work.
    Steps:
    1. Syncs s3 dir strucure into local disk using s3 sync.
    """
    hname = get_instance_hostname()
    s3Dir = "s3://%s/%s/%s%s" % (bucketName, hname, restoreDate, localDir)
    msg = "Restoring %s to %s from date %s" % (s3Dir, localDir, restoreDate)
    print msg
    logger.info(msg)
    cmd = "aws s3 sync --delete %s %s" % (s3Dir, localDir)
    msg = "Command: %s" % cmd
    logger.info(msg)
    
    if run_cmd(cmd):
        msg = 'Restore Success!'
        print msg
        logger.info(msg)
    else:
        msg = 'Restore Fail!'
        print msg
        logger.error(msg)

def run_cmd(cmd):
    """
    Function to run shell command and return success or failure status using
    returncode parameter.
    shlex.split() splits commands into lists readable by Popen command. Hence, 
    avoiding the risk of using shell=True.
    """
    hname = get_instance_hostname()
    cmd_list = shlex.split(cmd)
    p = Popen(cmd_list, stdout=PIPE, stderr=PIPE)
    out, err = p.communicate()
    if err:
        msg = err
        logger.error(msg)
    else:
        msg = out
        if " ls " in cmd and hname in cmd:
            print out
        else:
            logger.info(out)
    return p.returncode == 0

def exit(exitcode):
    """
    Function to print help text and then exit with the given exit code.
    """
    print "---"
    parser.print_help(sys.stderr)
    sys.exit(exitcode)

def program_exists(program):
    """
    Function to check if a command exists. 
    Used to check awscli installation.
    """
    cmd = '/usr/bin/which %s' % program
    return run_cmd(cmd)

def get_backup_dates(localDir):
    """
    Function to retrieve all dates on which the folder was backed up
    """
    hname = get_instance_hostname()
    cmd = "aws s3 ls --recursive s3://%s/%s | grep %s | awk '{print $1}' | sort | uniq" % (\
            bucketName, hname, localDir)
    dates = get_output(cmd).splitlines()
    return dates

def remove_path(date, localDir):
    """
    Function to remove an s3 path. This is being used to remove old backups based on 
    retention_days parameter. Default value for retention_days=10
    """
    hname = get_instance_hostname()
    cmd = "aws s3 rm --recursive s3://%s/%s/%s/%s" % (bucketName, hname, date, localDir)
    logger.info(cmd)

    if run_cmd(cmd):
        msg = "Cleared old backups of %s" % date
        logger.info(msg)
        return True
    else:
        msg = "Failed to clear old backup from %s" % date
        logger.error(msg)
        return False

def date_diff(date1, date2):
    """
    Function to get difference between two given dates.
    Use to get date difference while deciding whether to remove
    old backup or not. Default retention_days=10.
    """
    y1, m1, d1 = map(int, date1.split('-'))
    y2, m2, d2 = map(int, date2.split('-'))
    d0 = date(y1, m1, d1)
    d1 = date(y2, m2, d2)
    delta = d1 - d0
    return abs(delta.days)

def remove_old_backups(localDir):
    """
    Wrapper function to remove all old backups which
    have crossed the indicated by `retention_days` paramater.
    """
    backup_dates = get_backup_dates(localDir)
    today = get_current_date()
    for date in backup_dates:
        if date_diff(today, date) > retention_days:
            if not remove_path(date, localDir):
                msg = "Error removing backup for %s" % date
                logger.warning(msg)
                break
def force(action, remotePath, localPath):
    if action == 'backup':
        cmd = "aws s3 sync --delete %s %s" % (localPath, remotePath)
    elif action == 'restore':
        cmd = "aws s3 sync --delete %s %s" % (remotePath, localPath)
    if run_cmd(cmd):
        msg = "Force Backup/Restore Successful!"
    else:
        msg = "Force Backup/Restore Failed!"
    print msg
    logger.info(msg)

def ensure(bucketName):
        cmd = "aws s3 ls s3://%s" % bucketName
        if not run_cmd(cmd):
            esg = "Bucket %s does not exist. Creating.." % bucketName
            print msg
            logger.info(msg)
            cmd = "aws s3 mb --region %s s3://%s" % (region, bucketName)
            run_cmd(cmd)
        else:
            msg = "Bucket %s exists. Skipping creation." % bucketName
            print msg
            logger.info(msg)
    
def main():
    """
    Entrypoint function main()
    Arguments:
    -p/--path : Absolute path of the directory to be backed up.
    -b/--backup: Flag indicating backup option.
    -l/--list: Flag indicating listing option. Lists all objects under
               mentioned s3 path.
    -r/--restore: Flag indicating restore option.
    -d/--date: Argument required with -r/--restore flag. Indicates the date
               from which backup is to be restored.
    -z/--latest: Alternative option for -d/--date. Indicates latest backup
                 date as the restore date.
    -x/--retention: No. of days through which backup needs to be retained.
    -f/--force: Force sync directories to and from s3.
                This would need the s3path and local dir path to be absolute.
    -o/--remote: Remote path for sync. Set this for force sync. 
                 Required param if -f/--force is set.
    """
    parser.add_argument('-p', '--path', help='Absolute directory path to be \
            backed up or restored to.')
    parser.add_argument('-b', '--backup', action='store_true')
    parser.add_argument('-l', '--list', action='store_true', help='List all \
            objects in the path')
    parser.add_argument('-r', '--restore', action='store_true')
    parser.add_argument('-z', '--latest', action='store_true', help='Restore \
            from the latest backup.')
    parser.add_argument('-d', '--date', help='date from which to restore.')
    parser.add_argument('-s', '--s3bucket', help='s3bucket to store backups.')
    parser.add_argument('-x', '--retention_days', help='No. of days to retain \
            backup. Default 10 days')
    parser.add_argument('-f', '--force', action='store_true', help='Force sync source and \
            destination. Required params -p/--path, -o/--remote.')
    parser.add_argument('-o', '--remote', help='Remote s3path to restore \
            backup from. This is a required param if -f/--force is set.')
    args = parser.parse_args()

    msg = "\n\n--- Start ---"
    print msg
    logger.info(msg)

    if not program_exists('aws'):
        """
        Steps to correctly install and configure awscli.
        """
        msg = "Missing awscli.\n"
        msg += "Steps to install:\n"
        msg += "sudo apt-get install python-pip\n"
        msg += "sudo pip install awscli"
        print msg
        logger.error(msg)
        sys.exit(1)

    if args.retention_days:
        global retention_days
        retention_days = args.retention_days

    if args.s3bucket:
        global bucketName
        bucketName = args.s3bucket
        ensure(bucketName)

    elif args.force:
        msg = "Proceeding with mentioned remote"
        print msg
        logger.info(msg)
    else:
        msg = "Missing parameter <-s/--s3bucket>. S3 bucket to store backups."
        print msg
        logger.error(msg)
        exit(1)

    if args.list:
        hname = get_instance_hostname()
        msg = "Listing under s3path: s3://%s/%s" % (bucketName, hname)
        print msg
        logger.info(msg)
        cmd = "aws s3 ls --recursive s3://%s/%s" % (bucketName, hname)
        run_cmd(cmd)
        sys.exit(0)

    if not args.path:
        msg = "Missing parameters. Set <-p/--path>. Eh?"
        print msg
        logger.error(msg)
        exit(1)
    else:
        global localDir
        localDir = args.path.rstrip('/')
        if args.backup and args.restore:
            msg = "Too many flags. Select one of (-b/--backup, -r/--restore)"
            print msg
            logger.error(msg)
            exit(1)
        elif not args.backup and not args.restore:
            msg = "Missing flag. Select one of (-b/--backup, -r/--restore)"
            print msg
            logger.error(msg)
            exit(1)
        else:
            if args.backup:
                if args.force:
                    if not args.remote:
                        msg = "Missing params -o/--remote."
                        print msg
                        logger.error(msg)
                    else:
                        remotePath = args.remote.rstrip('/')
                        force('backup', remotePath, localPath)
                else:
                    backup(localDir)
            elif args.restore:
		if args.force:
                    if not args.remote:
                        msg = "Missing param -o/--remote."
                        print msg
                        logger.error(msg)
                    else:
                        remotePath = args.remote.rstrip('/')
                        force('restore', remotePath, localPath)
		else:
                    if not args.date and not args.latest:
                        msg = "Missing paramater. Set <-t/--date>.\n"
                        msg += "Backup date in YYYY-MM-DD format.\n"
                        msg += "Set flag <-z/--latest> for latest backup"
                        print msg
                        logger.error(msg)
                        exit(1)
                    elif args.latest:
                        restoreDate = get_latest_backup_date(localDir)
                    else:
                        restoreDate = args.date
                    restore(localDir, restoreDate)

if __name__ == '__main__':
    main()
